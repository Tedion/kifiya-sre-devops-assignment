# Alertmanager Configuration
# Production-ready alert routing, grouping, and notification setup

global:
  # Default SMTP configuration for email alerts
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'YOUR_SMTP_PASSWORD'
  smtp_require_tls: true

  # Slack webhook URL (can be overridden per receiver)
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

  # PagerDuty integration key
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

  # Default resolution timeout
  resolve_timeout: 5m

# Templates for notification messages
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert distribution
route:
  # Default receiver for all alerts
  receiver: 'default-receiver'
  
  # Group alerts by these labels
  group_by: ['alertname', 'cluster', 'service']
  
  # Wait time before sending first notification for a group
  group_wait: 30s
  
  # Wait time before sending notification about new alerts added to group
  group_interval: 5m
  
  # Minimum time between notifications for same group
  repeat_interval: 4h

  # Child routes with specific matching
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      group_interval: 2m
      repeat_interval: 30m
      continue: true  # Also send to default receiver
      routes:
        # Critical infrastructure issues - page on-call
        - match:
            category: infrastructure
          receiver: 'pagerduty-critical'
          group_wait: 5s
          repeat_interval: 15m

        # Critical application issues
        - match:
            category: application
          receiver: 'slack-engineering-critical'
          group_wait: 5s

        # Critical database issues
        - match:
            category: database
          receiver: 'dba-critical'
          group_wait: 5s

    # Warning alerts - standard notification
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 5m
      group_interval: 10m
      repeat_interval: 12h

    # Infrastructure alerts
    - match:
        category: infrastructure
      receiver: 'slack-platform'
      routes:
        - match:
            team: platform
          receiver: 'email-platform-team'

    # Application alerts
    - match:
        category: application
      receiver: 'slack-engineering'
      routes:
        - match:
            team: engineering
          receiver: 'email-engineering-team'

    # Database alerts
    - match:
        category: database
      receiver: 'slack-dba'
      routes:
        - match:
            team: dba
          receiver: 'email-dba-team'

    # Business alerts - notify product team
    - match:
        category: business
      receiver: 'slack-product'
      routes:
        - match:
            team: product
          receiver: 'email-product-team'

    # Kubernetes alerts
    - match:
        category: kubernetes
      receiver: 'slack-platform'

    # Silence development/staging alerts during off-hours
    - match:
        environment: staging
      receiver: 'slack-dev'
      group_wait: 10m
      repeat_interval: 24h

# Inhibition rules - suppress certain alerts when others are firing
inhibit_rules:
  # Inhibit any alert if the entire node is down
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '.+'
    equal: ['instance']

  # Inhibit critical alerts when service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      severity: 'warning'
    equal: ['service', 'instance']

  # Inhibit warning alerts when critical alerts are firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

# Receivers - notification integrations
receivers:
  # Default receiver - catch-all
  - name: 'default-receiver'
    email_configs:
      - to: 'devops-team@example.com'
        headers:
          Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        html: |
          {{ range .Alerts }}
          <b>Alert:</b> {{ .Labels.alertname }}<br>
          <b>Severity:</b> {{ .Labels.severity }}<br>
          <b>Instance:</b> {{ .Labels.instance }}<br>
          <b>Description:</b> {{ .Annotations.description }}<br>
          <b>Runbook:</b> <a href="{{ .Annotations.runbook }}">{{ .Annotations.runbook }}</a><br>
          {{ end }}

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#alerts-critical'
        title: 'üö® CRITICAL Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Instance:* {{ .Labels.instance }}
          *Description:* {{ .Annotations.description }}
          *Runbook:* {{ .Annotations.runbook }}
          {{ end }}
        send_resolved: true
    email_configs:
      - to: 'oncall@example.com'
        headers:
          Subject: 'üö® [CRITICAL] {{ .GroupLabels.alertname }}'

  # PagerDuty for critical infrastructure
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ .GroupLabels.alertname }}: {{ .Annotations.description }}'
        severity: 'critical'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          instance: '{{ .GroupLabels.instance }}'
        client: 'Prometheus Alertmanager'
        client_url: 'https://prometheus.example.com'

  # Warning alerts
  - name: 'warning-alerts'
    slack_configs:
      - channel: '#alerts-warning'
        title: '‚ö†Ô∏è Warning Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Instance:* {{ .Labels.instance }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

  # Platform team notifications
  - name: 'slack-platform'
    slack_configs:
      - channel: '#team-platform'
        title: 'Platform Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Severity:* {{ .Labels.severity }}
          *Instance:* {{ .Labels.instance }}
          *Description:* {{ .Annotations.description }}
          *Runbook:* {{ .Annotations.runbook }}
          {{ end }}

  - name: 'email-platform-team'
    email_configs:
      - to: 'platform-team@example.com'

  # Engineering team notifications
  - name: 'slack-engineering'
    slack_configs:
      - channel: '#team-engineering'
        title: 'Application Alert: {{ .GroupLabels.alertname }}'

  - name: 'slack-engineering-critical'
    slack_configs:
      - channel: '#engineering-critical'
        title: 'üö® CRITICAL Application Alert'
        color: 'danger'

  - name: 'email-engineering-team'
    email_configs:
      - to: 'engineering-team@example.com'

  # DBA team notifications
  - name: 'slack-dba'
    slack_configs:
      - channel: '#team-dba'
        title: 'Database Alert: {{ .GroupLabels.alertname }}'

  - name: 'dba-critical'
    slack_configs:
      - channel: '#dba-critical'
        title: 'üö® CRITICAL Database Alert'
    email_configs:
      - to: 'dba-oncall@example.com'

  - name: 'email-dba-team'
    email_configs:
      - to: 'dba-team@example.com'

  # Product team notifications
  - name: 'slack-product'
    slack_configs:
      - channel: '#team-product'
        title: 'Business Metric Alert: {{ .GroupLabels.alertname }}'

  - name: 'email-product-team'
    email_configs:
      - to: 'product-team@example.com'

  # Development/Staging alerts
  - name: 'slack-dev'
    slack_configs:
      - channel: '#alerts-staging'
        title: 'Staging Alert: {{ .GroupLabels.alertname }}'